%\documentclass[6pt]{article}
\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{multicol}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{bm}
\usepackage{bbm}
\usepackage{xparse}
\usepackage{physics}
\usepackage{empheq}
\usepackage{url}
\usepackage{hyperref}
\usepackage[affil-it]{authblk}
\usepackage{enumitem}
\usepackage{tikz}
\usetikzlibrary{quotes,angles,calc}
\usepackage{rotating}
\usepackage{graphicx}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output

\usepackage{pgfplots}
\pgfplotsset{compat = newest}

%\usepackage{wasysym}
%\usepackage{listings}
%\usepackage{moreverb}

%\usepackage[top=3cm,bottom=2cm,right=1cm,left=1cm]{geometry}
\usepackage[top=3cm,bottom=2cm,right=2cm,left=2cm]{geometry}

\theoremstyle{definition}
\newtheorem{theo}{Theorem}[section]
\newtheorem{lem}[theo]{Lemma}
\newtheorem{cor}[theo]{Corollary}
\newtheorem{prop}[theo]{Property}
\newtheorem{defi}[theo]{Definition}
\newtheorem{conj}[theo]{Conjecture}

\newtheorem{theo*}{Theorem}

\theoremstyle{remark}
\newtheorem*{rk}{Remark}

\DeclareMathOperator{\Poi}{\text{Poi}}
\DeclareMathOperator{\Ber}{\text{Ber}}
\DeclareMathOperator{\Bin}{\text{Bin}}
\DeclareMathOperator{\maxi}{\text{maximize}}
\DeclareMathOperator{\mini}{\text{minimize}}
\DeclareMathOperator{\st}{\text{subject to}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\DeclarePairedDelimiterX\set[1]\lbrace\rbrace{\def\given{\;\delimsize\vert\;}#1}

\newcommand{\OF}[1]{\textcolor{blue}{OF: #1}}

\colorlet{darkgreen}{green!40!black}

\title{\huge{Tight Approximation Guarantees for \\ Concave Coverage Problems}}
%\title{\huge{Tight Approximation Bounds for nondecreasing concave $\varphi$-\textsc{MaxCoverage}}}
\author{Siddharth Barman\footnote{Indian Institute of Science, Bangalore, India. \href{mailto:barman@iisc.ac.in}{\texttt{barman@iisc.ac.in}}} \space\space\space\space\space Omar Fawzi\footnote{Univ Lyon, ENS Lyon, UCBL, CNRS, LIP, F-69342, Lyon Cedex 07, France. \href{mailto:omar.fawzi@ens-lyon.fr}{\texttt{omar.fawzi@ens-lyon.fr}}}\space\space\space\space\space Paul Ferm√©\footnote{ENS Lyon, LIP, France. \href{mailto:paul.ferme@ens-lyon.fr}{\texttt{paul.ferme@ens-lyon.fr}}}
}
\date{}



\begin{document}

\begin{figure}[!h]
  \begin{center}
    \begin{tabular}{|l|l|l|l|l|}
      \hline
      $\varphi$-\textsc{MaxCoverage}  & $\varphi(j)$ & $\alpha_{\varphi}$ & Proof & Reference \\
      \hline
      \textsc{MaxCoverage} & $\min \{ j,1\}$ & $1 - e^{-1}$ & \ref{prop:lCover} & e.g. \cite{Hochbaum96} \\
      $\ell$-\textsc{MultiCoverage} & $\min\{ j,\ell\}$ & $1-\frac{\ell^{\ell}e^{-\ell}}{\ell!}$ & \ref{prop:lCover} & \cite{BFGG20}\\
      $p$-\textsc{Vehicle-Target Assignment} & $\frac{1-(1-p)^j}{p}$ & $\frac{1 - e^{-p}}{p}$ & \ref{prop:VTA} & \cite{Murphey00} \\
      $0.1$-\textsc{Vehicle-Target Assignment} & $\frac{1-(1-0.1)^j}{0.1}$ & $\frac{1 - e^{-0.1}}{0.1} \simeq 0.9516\ldots$ & - & - \\
      $0.1$-\textsc{Vehicle-Target Assignment}$_5$ & $\frac{1-(1-0.1)^{\min(j,5)}}{0.1}$ & $\alpha_{\varphi}(5) \simeq 0.8470\ldots$ & - & - \\
      \textsc{Proportional Approval Voting} & $\sum_{i=1}^j \frac{1}{i}$ & $\alpha_{\varphi}(1) \simeq 0.7965\ldots$ & - & \cite{DDMS20} \\
      \textsc{Proportional Approval Voting}$_3$ & $\sum_{i=1}^{\min(j,3)} \frac{1}{i}$ & $\alpha_{\varphi}(1) \simeq 0.7910\ldots$ & - & - \\
      $p$-\textsc{Harmonic} & $\sum_{i=1}^j \frac{1}{i^p}$ & $e^{-1}\sum_{k=1}^{+\infty}\frac{\varphi(k)}{k!}$ & - & \cite{DDMS20} \\
      $d$-Power & $j^d$ & $e^{-1}\sum_{k=1}^{+\infty}\frac{k^d}{k!}$ & \ref{prop:dPower} & \cite{PM19} \\
      \hline
    \end{tabular}
  \end{center}
  \caption{Our tight approximation ratios for particular choices of $\varphi$ in the $\varphi$-\textsc{MaxCoverage} problem.}
  \label{figComp}
\end{figure}

REMARK:
\[\varphi_m(j) := \varphi(\min(j,m))\]
truncated version of $\varphi$. We have:

\[ \alpha_{\varphi_m}(x) = \frac{\varphi(m) - e^{-x}\sum_{k=0}^{m-1} (\varphi(m)-\varphi(k))\frac{x^k}{k!}}{\varphi(x)} \]

(finite formula, and minimum between $1$ and $m$: we can find numerically argmin, and get exact expression of $\alpha_{\varphi}$: this is how we got the values of those cases in the table)

\begin{figure}[!h]
      \begin{center}
       \begin{tikzpicture}
          \begin{axis}[
            xmin = 0, xmax = 1,
            ymin = 0.5, ymax = 1,
            xtick distance = 0.2,
            ytick distance = 0.1,
            grid = both,
            width = 0.52\textwidth,
            height = 0.33\textwidth,
            legend cell align = {left},
            legend pos = north east,
            xlabel=$p$,
            ]
            \addplot[
              domain = 0:1,
              samples = 21,
              smooth,
              black,
              mark = x,
            ] table[x=p,y=alpha,col sep=comma] {VTAPoA.csv};
            \addplot[
              domain = 0:1,
              samples = 21,
              smooth,
              blue,
              mark = o,
            ] table[x=p,y=PoA,col sep=comma] {VTAPoA.csv};
            \addplot[
              domain = 0:1,
              samples = 21,
              smooth,
              red,
              mark = diamond,
            ] table[x=p,y=App,col sep=comma] {VTAPoA.csv};
            \legend{$\alpha_{\varphi^p} = \frac{1 - e^{-p}}{p}$, PoA$^{20}$,App $=1 - \frac{c}{e}$}
          \end{axis}
       \end{tikzpicture}
    \end{center}
    \caption{Comparison between the PoA and $\alpha_{\varphi}$ for the \textsc{Vehicle-Target Assignment} problem. Using the linear program found in \cite{PM19}, we were able to compute the blue curve PoA$^{20}$, the \emph{Price of Anarchy} of this problem for $m=20$ players. Since it only decreases when the number of players grows, this means that PoA $< \alpha_{\varphi}$ in that case, and thus the known inequality is not tight. As a comparison, the red curve App depicts the general approximation ratio (see \cite{SVW17}) obtained for submodular function with curvature $c$, with $c=1-\varphi^p(m) + \varphi^p(m-1)$ here.}
    \label{figVTA}
\end{figure}

%d-Power
\begin{figure}[!h]
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
          xmin = 0, xmax = 1,
          ymin = 0.5, ymax = 1,
          xtick distance = 0.2,
          ytick distance = 0.1,
          grid = both,
          width = 0.52\textwidth,
          height = 0.33\textwidth,
          legend cell align = {left},
          legend pos = north west,
          xlabel=$d$,
        ]
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          black,
          mark = x,
        ] table[x=d,y=alpha,col sep=comma] {dPowerPoA.csv};
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          blue,
          mark = o,
        ] table[x=d,y=PoA,col sep=comma] {dPowerPoA.csv};
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          red,
          mark = diamond,
        ] table[x=d,y=App,col sep=comma] {dPowerPoA.csv};
        \legend{$\alpha_{\varphi^d} = \frac{1}{e}\sum_{k=1}^{+\infty}\frac{k^d}{k!}$, PoA$^{20}$, App $=1 - \frac{c}{e}$}
      \end{axis}
    \end{tikzpicture}
  \end{center}
  \caption{Comparison between the PoA and $\alpha_{\varphi}$ for the $d$-Power problem. Using the linear program found in \cite{PM19}, we were able to compute the blue curve PoA$^{20}$, the \emph{Price of Anarchy} of this problem for $m=20$ players. Here, the question whether the inequality PoA $\leq \alpha_{\varphi}$ is tight remains open. As a comparison, the red curve App depicts the general approximation ratio (see \cite{SVW17}) obtained for submodular function with curvature $c$, with $c=1-\varphi^d(m) + \varphi^d(m-1)$ here.}
  \label{figdPower}
\end{figure}

%VTA VS VTA truncated
\begin{figure}[!h]
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
          xmin = 0, xmax = 1,
          ymin = 0.5, ymax = 1,
          xtick distance = 0.2,
          ytick distance = 0.1,
          grid = both,
          width = 0.52\textwidth,
          height = 0.33\textwidth,
          legend cell align = {left},
          legend pos = outer north east,
          xlabel=$p$,
        ]
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          black,
          mark = x,
        ] table[x=p,y=alpha,col sep=comma] {VTATruncPlot.csv};
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          brown,
          mark = triangle,
        ] table[x=p,y=m1,col sep=comma] {VTATruncPlot.csv};
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          orange,
          mark = o,
        ] table[x=p,y=m2,col sep=comma] {VTATruncPlot.csv};
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          purple,
          mark = diamond,
        ] table[x=p,y=m3,col sep=comma] {VTATruncPlot.csv};
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          red,
          mark = square,
        ] table[x=p,y=m4,col sep=comma] {VTATruncPlot.csv};
        \addplot[
          domain = 0:1,
          samples = 21,
          smooth,
          blue,
          mark = star,
        ] table[x=p,y=m5,col sep=comma] {VTATruncPlot.csv};

        \legend{$\alpha_{\varphi^p_{\infty}} = \frac{1 - e^{-p}}{p}$, $\alpha_{\varphi^p_{1}} = 1- e^{-1}$, $\alpha_{\varphi^p_{2}}$, $\alpha_{\varphi^p_{3}}$, $\alpha_{\varphi^p_{4}}$, $\alpha_{\varphi^p_{5}}$ }
      \end{axis}
    \end{tikzpicture}
  \end{center}
  \caption{Comparison of $\alpha_{\varphi^p_m}$, where $m$ is the rank of the truncated version of the $p$-\textsc{Vehicle-Target Assignment} problem. When $p=0$, we recover the $m$-coverage problem. All the cases with $1<m<\infty$ and $p \in  ]0,1[$ are new.}
\end{figure}
  
\bibliographystyle{plain}
\bibliography{these.bib}

\newpage
\appendix

\section{General properties}
\begin{prop}
  $C^{\varphi}$ is submodular, its curvature is at most $c = 1 - (\varphi(m) - \varphi(m-1))$ and it cannot be improved for a general instance with $m$ cover sets.
  \label{prop:SubCurv}
\end{prop}

\begin{proof}

  We use the following lemma which is trivial to prove:

  \begin{lem}[Properties of $\abs{S}_a = \abs{\set{i \in S : a \in T_i}}$.]
    We have:
  \begin{enumerate}
  \item $\abs{S}_a \leq \abs{S}$
  \item $\abs{S \cup S'}_a\leq \abs{S}_a + \abs{S'}_a$. In particular, if $S \subseteq T$ then $\abs{S}_a \leq \abs{T}_a$ and $\abs{S\cup\set{x}}_a \leq \abs{S}_a + 1$.
  \item If $S \subseteq T$, $x \not\in T$ then $\abs{S}_a = \abs{T}_a \Rightarrow \abs{S\cup\set{x}}_a = \abs{T\cup\set{x}}_a$
  \end{enumerate}
  \label{lem:ke}
\end{lem}
  
  Let us show first the submodularity of $C^{\varphi}$. Let $S \subseteq T \subseteq [m]$ and $x \not\in T$:
  \begin{equation}
    \begin{aligned}
      &&& C^{\varphi}(S \cup \set{x}) - C^{\varphi}(S) - (C^{\varphi}(T \cup \set{x}) - C^{\varphi}(T))= \\
      &=&& \sum_{a \in [n]} w_a[\varphi(\abs{S\cup\set{x}}_a) - \varphi(\abs{S}_a) - (\varphi(\abs{T\cup\set{x}}_a) - \varphi(\abs{T}_a))]\\
    \end{aligned}
  \end{equation}

  Let us call $g(a) := \varphi(\abs{S\cup\set{x}}_a) - \varphi(\abs{S}_a) - (\varphi(\abs{T\cup\set{x}}_a) - \varphi(\abs{T}_a))$:
  \begin{enumerate}
  \item If $\abs{T}_a = \abs{S}_a$ then thanks to lemma \ref{lem:ke}, we have that $\abs{T\cup\set{x}}_a = \abs{S\cup\set{x}}_a$, so $g(a) = 0$
  \item Else, we have that $\abs{T}_a > \abs{S}_a$:
    \begin{enumerate}
    \item If $\abs{S\cup\set{x}}_a = \abs{S}_a$, then we add elements of $T-S$ using lemma \ref{lem:ke} to get that $\abs{T\cup\set{x}}_a = \abs{T}_a$, so $g(a)=0$ in that case.
    \item Else $\abs{S\cup\set{x}}_a \not= \abs{S}_a$. So with $\abs{S}_a = k$, we get that $\abs{S\cup\set{x}}_a = k+1$ and $\abs{T}_a > \abs{S}_a$ so $\abs{T}_a \geq k+1$.

      \begin{enumerate}
      \item If $\abs{T\cup\set{x}}_a = \abs{T}_a$, then $g(a) =  \varphi(k+1) - \varphi(k) \geq 0$ since $\varphi$ is nondecreasing.
      \item Else $\abs{T\cup\set{x}}_a \not= \abs{T}_a$ so with $\abs{T}_a = \ell$ with $\ell \geq k+1$, we get that $\abs{T}_a = \ell+1$. So we have that:
        \begin{equation}
          \begin{aligned}
            g(a) &=&& \varphi(k+1) - \varphi(k) - (\varphi(\ell+1) - \varphi(\ell))\\
            &=&& \frac{\varphi(k+1) - \varphi(k)}{(k+1) - k} - \frac{\varphi(\ell+1) - \varphi(\ell)}{(\ell+1) - \ell} \geq 0
          \end{aligned}
        \end{equation}
        by concavity of $\varphi$: its slopes are nonincreasing.
      \end{enumerate}
    \end{enumerate}
  \end{enumerate}
  So in all cases, we have $g(a) \geq 0$ so $ C^{\varphi}(S \cup \set{x}) - C^{\varphi}(S) - (C^{\varphi}(T \cup \set{x}) - C^{\varphi}(T)) \geq 0$: $C^{\varphi}$ is submodular.

  Let us now compute its curvature:
  \[c = 1 - \min_{i \in [m]} \frac{C^{\varphi}([m]) - C^{\varphi}([m]-\set{i})}{C^{\varphi}(\set{i}) - C^{\varphi}(\emptyset)}\]

  Let $i \in [m]$ fixed:
  \begin{equation}
    \begin{aligned}
      &&& \frac{C^{\varphi}([m]) - C^{\varphi}([m]-\set{i})}{C^{\varphi}(\set{i}) - C^{\varphi}(\emptyset)}\\
      &=&& \frac{\sum_{a \in [n]} w_a[\varphi(\abs{[m]}_a) - \varphi(\abs{[m]-\set{i}}_a)]}{\sum_{a \in [n]}w_a[\varphi(\abs{\set{i}}_a) - \varphi(\abs{\emptyset}_a)]}\\
      &=&& \frac{\sum_{a \in T_i} w_a[\varphi(\abs{[m]}_a) - \varphi(\abs{[m]-\set{i}}_a)]}{\sum_{a \in T_i} w_a}\\
      &=&& \frac{\sum_{a \in T_i} w_a[\varphi(\abs{[m]}_a) - \varphi(\abs{[m]}_a-1)]}{\sum_{a \in T_i} w_a} \text{ since } a \in T_i\\
    \end{aligned}
  \end{equation}

  But $\abs{[m]}_a \leq m$ and $\varphi$ concave, so $\varphi(\abs{[m]}_a)) - \varphi(\abs{[m]}_a-1) \geq \varphi(m) - \varphi(m-1)$ for all $a \in [n]$. As a consequence we have that:

  \[\frac{C^{\varphi}([m]) - C^{\varphi}([m]-\set{i})}{C^{\varphi}(\set{i}) - C^{\varphi}(\emptyset)} \geq \varphi(m) - \varphi(m-1)\]
  
  and this lower bound is true for its minimum over $i$. Thus we get that $c \leq 1 - (\varphi(m) - \varphi(m-1))$.
  Also one can find instances for all $m$ such that this bound is tight: take $T_1 =\set{a}$ and $\forall j \in [m], a \in T_j$ for instance.
\end{proof}

\begin{prop}
  The approximation ratio $\alpha_{\varphi}$ is always better than the general ratio given in $\cite{SVW17}$: $\min_{x \in [m]} \alpha_{\varphi}(x) \geq 1 - ce^{-1}$ with $1-c = \varphi(m) - \varphi(m-1)$. Furthermore, we have always that $\alpha_{\varphi}(0) = 1$, so the minimum range in the definition of $\alpha_{\varphi}$ can be taken on positive integers only.
  \label{prop:BetterRatio}
\end{prop}

\begin{proof}
  We first suppose that $x \geq 1$. Also, we can ask that for all $j \geq m$, we have $\varphi(j+1) -\varphi(j) = \varphi(m) -\varphi(m-1)$, since these quantities are never achieved in a instance with $m$ cover sets. So we can suppose that for all $j$ we have $\varphi(j+1) -\varphi(j) \geq \varphi(m) -\varphi(m-1)$. Also for $k \geq 1$, one can write:

  \[\varphi(k)= \sum_{j=0}^{k-1} \varphi(j+1) -\varphi(j) = 1 + \sum_{j=1}^{k-1} \varphi(j+1) -\varphi(j) \]
  
  Thus:
  
  \begin{equation}
    \begin{aligned}
      &&&\mathbb{E}[\varphi(\Poi(x))] = e^{-x}\sum_{k=1}^{+\infty}\varphi(k) \frac{x^k}{k!}\\
      &=&& e^{-x}\sum_{k=1}^{+\infty}\Big(1 + \sum_{j=1}^{k-1} \varphi(j+1) -\varphi(j)\Big) \frac{x^k}{k!} \\
      &=&& e^{-x}\Big[(e^x - 1) + \sum_{k=1}^{+\infty}\Big(\sum_{j=1}^{k-1} \varphi(j+1) -\varphi(j)\Big) \frac{x^k}{k!} \Big]\\
      &\geq&& (1 - e^{-x}) + e^{-x}\sum_{k=1}^{+\infty}(k-1)[\varphi(m) -\varphi(m-1)] \frac{x^k}{k!}\\
      &=&& (1 - e^{-x}) + [1-c]e^{-x}\Big(x\sum_{k=1}^{+\infty}\frac{x^{k-1}}{(k-1)!} - \sum_{k=1}^{+\infty}\frac{x^k}{k!}\Big)\\
      &=&& (1 - e^{-x}) + [1-c]e^{-x}\Big(xe^x - (e^x-1)\Big)\\
      &=&& 1 - e^{-x} + [1-c](x-1 + e^{-x}) =: f(x)
    \end{aligned}
  \end{equation}

  But since $\varphi(x) \leq x$  and with $g(x) := \frac{f(x)}{x}$, we get that $g'(x) =\frac{c}{x^2}(x-1+e^{-x}) \geq 0$ for $x \geq 1$, thus $g(x) \geq g'(1)$ and then

  \[\alpha_{\varphi}(x) \geq \frac{f(x)}{\varphi(x)} \geq g(x) \geq g(1) = f(1) \]

  with $f(1) =  1 - e^{-1} + (\varphi(m) - \varphi(m-1)) e^{-1}$ the approximation ratio of the general algorithm.

  Let us now suppose that $x \in [0,1]$. We have that $\varphi(x) = x$ on that interval since we have taken its piecewise linear extension and $\varphi(0) = 0$ and $\varphi(1) = 1$. Thus we have that
  \[\alpha_{\varphi}(x) = \frac{\mathbb{E}[\varphi(\Poi(x))]}{x} = e^{-x}\sum_{k=1}^{+\infty}\frac{\varphi(k)}{k}\frac{x^{k-1}}{(k-1)!} \]

  and we can then compute its value at $0$: $\alpha_{\varphi}(0) = e^{-0}\sum_{k=1}^{+\infty}\frac{\varphi(k)}{k}\frac{0^{k-1}}{(k-1)!} = \frac{\varphi(1)}{1}\frac{0^0}{0!} = 1$. Since $\alpha_{\varphi}(x) \leq 1$, we have that $\alpha_{\varphi} = \inf_{x \in \mathbb{N}^*} \alpha_{\varphi}(x)$.
\end{proof}

\begin{lem}
    For $\varphi$ nondecreasing concave with $\varphi(0)=0,\varphi(1)=1$, we have that the function $g : x \mapsto \mathbb{E}[\varphi(\Poi(x))]$ on $\mathbb{R}^+$ is $\mathcal{C}^{\infty}$ nondecreasing concave.
    \label{lem:PoiCon}
  \end{lem}

  \begin{proof}
    Since we have that $\varphi(k) \leq k$ for $k \in \mathbb{N}$, in particular $g(x) = e^{-x}\sum_{k=0}^{+\infty} \varphi(k)\frac{x^k}{k!}$ is $\mathcal{C}^{\infty}$. It is thus enough to compute its first and second derivatives:

    \begin{equation}
      \begin{aligned}
        g'(x) &=&& -e^{-x}\sum_{k=0}^{+\infty}\varphi(k)\frac{x^k}{k!}+ e^{-x}\sum_{k=1}^{+\infty}\varphi(k)e^{-x}k\frac{x^{k-1}}{k!}\\
        &=&& -e^{-x}\sum_{k=0}^{+\infty}\varphi(k)\frac{x^k}{k!}+ e^{-x}\sum_{k=0}^{+\infty}\varphi(k+1)e^{-x}\frac{x^{k}}{k!}\\
        &=&& e^{-x}\sum_{k=0}^{+\infty}(\varphi(k+1) -\varphi(k))\frac{x^k}{k!}
      \end{aligned}
    \end{equation}

    But $\varphi(k+1) -\varphi(k) \geq 0$ since $\varphi$ nondecreasing, so $g'(x) \geq 0$ and $g$ is nondecreasing.

    
    The calculus of $g''$ is the same where we replace $\varphi$ by $\psi(k) := \varphi(k+1) -\varphi(k)$ which is a nonincreasing function by concavity of $\varphi$. Thus:

    \[g''(x) = e^{-x}\sum_{k=0}^{+\infty}(\psi(k+1) -\psi(k))\frac{x^k}{k!} \leq 0\]

    since $\psi(k+1) -\psi(k) \leq 0$, and so $g$ is concave.
  \end{proof}


  \begin{prop}
    For $\varphi$ nondecreasing concave with $\varphi(0)=0, \varphi(1)=1$ and $w_i = \varphi(i)-\varphi(i-1)$, we have:
    \[ \lim_{i \rightarrow +\infty} w_i = 0 \iff \varphi(n) = o(n) \]
    \label{prop:thieleEqLim}
  \end{prop}
  \begin{proof}
    \begin{itemize}
    \item[($\Rightarrow$)] Let $\epsilon > 0$, let us find a rank $N$ such that for $n \geq N$, $\frac{\varphi(n)}{n} \leq \epsilon$. Let $N_0$ the rank from which $w_i \leq \frac{\epsilon}{2}$ and $N_1$ the rank from which $\frac{1}{n} \sum_{i=1}^{N_0-1} w_i \leq \frac{\epsilon}{2}$. We have
      
      \begin{equation}
        \begin{aligned}
          \frac{\varphi(n)}{n} &=&& \frac{1}{n} \sum_{i=1}^{n} w_i \leq \frac{1}{n} \sum_{i=1}^{N_0-1} w_i + \frac{1}{n} \sum_{i=N_0}^{n-1} \frac{\epsilon}{2}\\
          &\leq&& \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon \text{ for } n \geq \max(N_0,N_1) =: N
        \end{aligned}
      \end{equation}
    \item[($\Leftarrow$)] Since $w_i = \varphi(i)-\varphi(i-1)$ is nonnegative and nonincreasing (respectively because $\varphi$ is nondecreasing and concave), then the sequence $w$ has a limit $L \geq 0$. But
      \[ \frac{\varphi(n)}{n} = \frac{1}{n} \sum_{i=1}^{n} w_i \geq L \]
      
      Since the left hand side tends to $0$ by hypothesis, this means that $L=0$.
    \end{itemize}
  \end{proof}

  \begin{prop}
    For $\varphi$ nonnegative and nondecreasing such that $\forall x \geq m, \varphi(x) = \varphi(m) > 0$, then $\alpha_{\varphi}(x)$ is nondecreasing from $m$ to $+\infty$ and $\alpha_{\varphi}(x) =  \frac{\varphi(m) - e^{-x}\sum_{k=0}^{m-1} (\varphi(m)-\varphi(k))\frac{x^k}{k!}}{\varphi(x)}$. In particular, $\alpha_{\varphi} = \min_{x \in [m]} \alpha_{\varphi}(x)$, and the argmin can be found numerically.
  \end{prop}
  
  \begin{proof}
    Let $x \geq m$, then:
    \[ \alpha_{\varphi}(x) = \frac{\mathbb{E}[\varphi(\Poi(x))]}{\varphi(x)} = \frac{e^{-x}\sum_{k=0}^{+\infty} \varphi(k)\frac{x^k}{k!}}{\varphi(m)} = \frac{e^{-x}\sum_{k=0}^{m-1} (\varphi(k)-\varphi(m))\frac{x^k}{k!} + \varphi(m)}{\varphi(m)} \]

    In particular, $\alpha_{\varphi}(x)$ is derivable and:

    \begin{equation}
      \begin{aligned}
        \alpha_{\varphi}'(x) &=&& -\frac{e^{-x}}{\varphi(m)}\sum_{k=0}^{m-1} (\varphi(k)-\varphi(m))\frac{x^k}{k!}  + \frac{e^{-x}}{\varphi(m)}\sum_{k=0}^{m-2} (\varphi(k+1)-\varphi(m))\frac{x^k}{k!}\\
        &=&& \frac{e^{-x}}{\varphi(m)}\sum_{k=0}^{m-1} (\varphi(k+1)-\varphi(k))\frac{x^k}{k!} \geq 0 \text{ since } \varphi \text{ nondecreasing }
      \end{aligned}
    \end{equation}

    Thus $\alpha_{\varphi}(x)$ is nondecreasing from $m$ to $+\infty$ and the result on $\alpha_{\varphi}$ follows.
  \end{proof}

\section{Proofs on calculus of $\alpha_{\varphi}$}
\begin{prop}
  For $\ell \in \mathbb{N}^*$ and $\varphi(j) = \min(j,\ell)$, we have that $\alpha_{\varphi}=1-\frac{\ell^{\ell}e^{-\ell}}{\ell!}$.
  \label{prop:lCover}
\end{prop}
\begin{proof}
  Thanks to property \ref{prop:BetterRatio}, we have that $\alpha_{\varphi} = \inf_{x \in \mathbb{N}^*} \alpha_{\varphi}(x)$. Let us compute $\mathbb{E}[\varphi(\Poi(x))]$:

  \begin{equation}
    \begin{aligned}
      \mathbb{E}[\varphi(\Poi(x))] &=&& e^{-x}\sum_{k=0}^{+\infty}\varphi(x)\frac{x^k}{k!}\\
      &=&& e^{-x}\sum_{k=0}^{\ell}k\frac{x^k}{k!} + e^{-x}\sum_{k=\ell+1}^{+\infty}\ell\frac{x^k}{k!}\\
      &=&& e^{-x}x \sum_{k=0}^{\ell-1}\frac{x^k}{k!} + \ell e^{-x}\sum_{k=\ell+1}^{+\infty}\frac{x^k}{k!}\\
      &=&& e^{-x}\Big[(x-\ell)\sum_{k=0}^{\ell-1}\frac{x^k}{k!} - \ell\frac{x^{\ell}}{\ell!}\Big] + \ell e^{-x}\sum_{k=0}^{+\infty}\frac{x^k}{k!}\\
      &=&& \ell - e^{-x}\Big[\frac{x^{\ell}}{(\ell-1)!} - (x-\ell)\sum_{k=0}^{\ell-1}\frac{x^k}{k!}\Big]
    \end{aligned}
  \end{equation}

  Let us show that $\alpha_{\varphi}(x)$ takes its minimum in $\ell$, where we have indeed:
  \[ \alpha_{\varphi}(\ell) = \frac{1}{\ell}\Big( \ell - e^{-\ell}\Big[\frac{\ell^{\ell}}{(\ell-1)!} - (\ell-\ell)\sum_{k=0}^{\ell-1}\frac{\ell^k}{k!}\Big]\Big) = 1 - e^{-\ell}\frac{\ell^{\ell}}{\ell!} \]

  $\alpha_{\varphi}(x)$ is derivable: let us compute it from $\ell$ to $+\infty$ and then from $1$ to $\ell$:

  \begin{equation}
    \begin{aligned}
      \alpha_{\varphi}'(x) &=&&  e^{-x}\Big[\frac{x^{\ell}}{\ell!} -  (x-\ell)\sum_{k=0}^{\ell-1}\frac{x^k}{\ell k!}\Big]\\ 
      &-&& e^{-x}\Big[\frac{x^{\ell-1}}{(\ell-1)!} - \sum_{k=0}^{\ell-1}\frac{x^k}{\ell k!} - (x-\ell)\sum_{k=0}^{\ell-2}\frac{x^{k}}{\ell k!} \Big] \\
      &=&& e^{-x}\Big[\frac{x^{\ell}}{\ell!} - \frac{x^{\ell-1}}{(\ell-1)!} -(x-\ell)\frac{x^{\ell-1}}{\ell!} + \sum_{k=0}^{\ell-1}\frac{x^k}{\ell k!} \Big]\\
      &=&& e^{-x}\sum_{k=0}^{\ell-1}\frac{x^k}{\ell k!} \geq 0
    \end{aligned}
  \end{equation}
  
  So  $\alpha_{\varphi}(x)$ is nondecreasing from $\ell$ to $+\infty$. Let's compute it now between $1$ and $\ell$:
  
  \begin{equation}
    \begin{aligned}
      \alpha_{\varphi}'(x) &=&& -\frac{\ell}{x^2} + e^{-x}\Big[\frac{x^{\ell-1}}{(\ell-1)!} -  \sum_{k=0}^{\ell-1}\frac{x^k}{k!}  + \ell\sum_{k=0}^{\ell-2}\frac{x^k}{(k+1)!} + \frac{\ell}{x}\Big]\\ 
      &-&& e^{-x}\Big[\frac{x^{\ell-2}}{(\ell-2)!} - \sum_{k=0}^{\ell-2}\frac{x^k}{k!} + \ell\sum_{k=0}^{\ell-3}\frac{x^k}{(k+2)k!} - \frac{\ell}{x^2}\Big]\\
      &=&&  \frac{\ell}{x}\Big(e^{-x}\Big(1+\frac{1}{x}\Big) - \frac{1}{x}\Big)\\
      &+&&  e^{-x}\Big[\Big(\frac{\ell}{\ell-1}-1\Big)\frac{x^{\ell-2}}{(\ell-2)!} + \ell\sum_{k=0}^{\ell-3}\Big(\frac{x^k}{(k+1)!} - \frac{x^k}{(k+2)k!} \Big) \Big]\\
      &=&&  \frac{\ell}{x}\Big(e^{-x}\Big(1+\frac{1}{x}\Big) - \frac{1}{x}\Big)\\
      &+&&  e^{-x}\Big[\frac{x^{\ell-2}}{(\ell-1)!} + \ell\sum_{k=0}^{\ell-3}\frac{x^k}{k!}\Big(\frac{1}{k+1} - \frac{1}{k+2} \Big) \Big]\\
      &=&&  \frac{\ell}{x}\Big(e^{-x}\Big(1+\frac{1}{x} + \frac{x^{\ell-1}}{\ell!} + x\sum_{k=0}^{\ell-3}\frac{x^k}{k!}\frac{1}{(k+1)(k+2)}\Big) - \frac{1}{x}\Big)\\
      &=&&  \frac{\ell e^{-x}}{x^2}\Big(\Big(1+x+ \frac{x^\ell}{\ell!} + \sum_{k=0}^{\ell-3}\frac{x^{k+2}}{(k+2)!}\Big) - e^x\Big)\\
      &=&& \frac{\ell e^{-x}}{x^2}\Big(\sum_{k=0}^{\ell} \frac{x^k}{k!} -e^x\Big) \leq 0
    \end{aligned}
  \end{equation}

  since the partial sum of the exponential series is bounded by its total sum. In order to make all this calculus correct, we need to ask that $\ell \geq 2$. In the case where $\ell=1$, we did not need to prove anything. Thus we have that $\alpha_{\varphi}(x)$ is nonincreasing from $1$ to $\ell$, and nondecreasing after, so it takes indeed its minimum in $\ell$ and the property is proved.
\end{proof}

\begin{prop}
  For $p \in ]0,1[$ and $\varphi(j)=\frac{1-(1-p)^j}{p}$, we have that $\alpha_{\varphi} = \frac{1 - e^{-p}}{p}$.
\label{prop:VTA}
\end{prop}

\begin{proof}
    By definition:
    
    \begin{equation}
      \begin{aligned}
        \alpha_{\varphi^p}(x) &=&& \frac{\mathbb{E}[\varphi^p(\Poi(x))]}{\varphi^p(x)} = \frac{\sum_{k=0}^{+\infty}\varphi^p(k)e^{-x}\frac{x^k}{k!}}{\varphi^p(x)}\\
        &=&& \frac{1-e^{-x}\sum_{k=0}^{+\infty}(1-p)^k\frac{x^k}{k!}}{p\varphi^p(x)}\\
        &=&& \frac{1 - e^{-x}e^{(1-p)x}}{p\varphi^p(x)} = \frac{1 - e^{-px}}{p\varphi^p(x)}
      \end{aligned}
    \end{equation}

    If $x \geq 1$, $\alpha_{\varphi^p}(x) = \frac{1 - e^{-px}}{1-(1-p)^x}$ and:

    \[\alpha_{\varphi^p}'(x) = \frac{pe^{-px}(1-(1-p)^x) - \ln(1-p)(1-p)^x(1-e^{-px})}{(1-(1-p)^x)^2}\]
    
    But $1-(1-p)^x > 0, 1-e^{-px} > 0, \ln(1-p) < 0$ since $x > 0$ and $p \in ]0,1[$, so $\alpha_{\varphi^p}'(x) > 0$ for $x \geq 1$ and so $\alpha_{\varphi^p}(x)$ increases from $1$ to infinity. Thus it takes indeed its minimum in $1$:
    
    \[\alpha_{\varphi^p} = \alpha_{\varphi^p}(1) = \frac{1 - e^{-p}}{p}\]
\end{proof}
\begin{prop}
  For $d \in ]0,1[$ and $\varphi(j)=j^d$, we have that $\alpha_{\varphi} = e^{-1}\sum_{k=1}^{+\infty}\frac{k^d}{k!}$
    \label{prop:dPower}
\end{prop}
\begin{proof}
  We have for $x \geq 1$:
    \[\alpha_{\varphi}(x) = \frac{\mathbb{E}[\Poi(x)^d]}{\varphi(x)} = \frac{e^{-x}\sum_{k=0}^{+\infty}k^d\frac{x^k}{k!}}{\varphi(x)} = e^{-x}\sum_{k=0}^{+\infty}k^d\frac{x^{k-d}}{k!} \]

   Then:
        
   \begin{equation}
     \begin{aligned}
       \alpha_{\varphi}'(x) &=&& -\alpha_{\varphi}(x)+ e^{-x}\sum_{k=1}^{+\infty}(k-d)k^d\frac{x^{k-d-1}}{k!} \\
       &=&& -\alpha_{\varphi}(x)+ e^{-x}\sum_{k=0}^{+\infty}(k+1-d)(k+1)^d\frac{x^{k-d}}{(k+1)!}\\
       &=&& -\alpha_{\varphi}(x)+ e^{-x}\Big((1-d)x^{-d} +  \sum_{k=1}^{+\infty}(k+1-d)(k+1)^{d-1}\frac{x^{k-d}}{k!}\Big)\\
       &=&& e^{-x}x^{-d}\Big(1-d + \sum_{k=1}^{+\infty}(\frac{k+1-d}{k+1}(k+1)^d - k^d)\frac{x^k}{k!}\Big)\\
     \end{aligned}
   \end{equation}

   But the function $f(k) = \frac{k+1-d}{k+1}(k+1)^d - k^d$ is positive on $\mathbb{R}_+^*$, so we get that $\alpha_{\varphi}'(x) > 0$ for $x \geq 1$, thus $\alpha_{\varphi}(x)$ is increasing from $1$ to $+\infty$, so $\alpha_{\varphi} = \alpha_{\varphi}(1) = e^{-1}\sum_{k=1}^{+\infty}\frac{k^d}{k!}$.
\end{proof}

\section{NP-hardness of $\delta,h$-\textsc{AryGapLabelCover}}
\label{NPhardnessGap}
\begin{proof}[Proof of property \ref{prop:AryGapLabelCover}]
  We reduce from the Label Cover problem described in \cite{DDMS20} which is known no be an NP-hard problem. The main idea of this reduction is the usual equivalence between a bipartite graph and a hypergraph.

  \begin{defi}
    A Label Cover instance $\mathcal{L} = (A,B,E,[L],[R],\set{\pi_e}_{e \in E})$ consists of a bi-regular bipartite graph $(A,B,E)$ with right degree $t$, alphabet sets $[L],[R]$ and for every edge $e \in E$, a constraint $\pi_e :[L] \rightarrow [R]$.
    A \emph{labelling} of $\mathcal{L}$ is a function $\sigma : A \rightarrow [L]$. We say that $\sigma$ \emph{strongly satisfies} a right vertex $v \in B$ if for every two neighbours $u,u'$ of $v$, we have $\pi_{(u,v)}(\sigma(u)) = \pi_{(u',v)}(\sigma(u'))$. Moreover, we say that  $\sigma$ \emph{weakly satisfies} a right vertex $v \in B$ if there exists two neighbours $u,u'$ of $v$ such that $\pi_{(u,v)}(\sigma(u)) = \pi_{(u',v)}(\sigma(u'))$.
  \end{defi}

 \begin{theo}[$\delta$-Gap-Label-Cover$(t,R)$ from \cite{DDMS20}]
  For any fixed integer $t \geq 2$ and fixed $\delta > 0$, there exists $R$ that can be taken as large as we want, such that it is NP-hard for Label Cover instances $\mathcal{L} = (A,B,E,[L],[R],\set{\pi_e}_{e \in E})$ with right degree $t$ to distinguish between:
  
  \begin{itemize}
  \item[\textbf{YES:}] There exists a labeling $\sigma$ that \emph{strongly satisfies} all the right vertices.
  \item[\textbf{NO:}] No labeling \emph{weakly satisfies} more than $\delta$ fraction of the right vertices.
  \end{itemize}
\end{theo}

 The reduction is the following. From $\delta$-Gap-Label-Cover$(t,R)$, we take $h=t$ and the same parameters $\delta,R$. Given an instance $\mathcal{L} = (A,B,E,[L],[R],\set{\pi_e}_{e \in E})$, we take $\mathcal{G} = (A,E',[L],[R],\set{\pi'_{e',v}}_{e' \in E',v \in e'})$ with $E' = \set{N(b), b \in B}$ with $N(b)$ the set of neighbours of $b$ in $\mathcal{L}$, and $\pi'_{e',v} = \pi'_{N(b),v} := \pi_{v,b}$ since $v \in N(b)$.
 Since $(A,B,E)$ is bipartite and biregular, we get that our hypergraph has all hyperedges of size $h = \abs{N(b)} = t$, and that it is regular from the regular left degree of $(A,B,E)$. By construction, the notion of weakly and strongly satisfied is the same in both cases, as well as the labellings, and thus we have the NP-hardness of $\delta,h$-\textsc{AryGapLabelCover}.
 
\end{proof}

\section{Proof of existence of partitioning systems}
\begin{proof}[Proof of property \ref{prop:Partitioning}]
    The existential proof is based on the probabilistic method. We take $\mathcal{P}_i$ an $h$-equi-sized uniform random $x_{\varphi}$-cover of $[n]$. Hence in the collection $\mathcal{P}_i=(P_{i,1},\ldots,P_{i,h})$, each of the $h$ subsets is of cardinality $x_{\varphi}n/h$. Write $\mathcal{P} = (\mathcal{P}_1,\ldots,\mathcal{P}_R)$. We have that for any $a \in [n], \mathbb{P}(a \in P_{i,j}) = x_{\varphi}/h$. We note that although for $i$ fixed those events are not independent, but for different $i$s, these events are independent.

    By construction, the first condition is fulfilled. In order to prove the second condition, we prove some bound on a fixed $T$ and $\mathcal{Q}$ and with union bound we will go over all of them.

    Let fix $T \subseteq [R]$ and $\mathcal{Q} := \set{P_i : i \in T}$ with $P_i :=P_{i, j(i)}$ for some function $j$.

    We have that for some $a \in [n]$:
    \[ \mathbb{E}[C_a^{\varphi}(\mathcal{Q})] =  \mathbb{E}[\varphi(\abs{\mathcal{Q}}_a)] = \mathbb{E}[\varphi(\abs{\set{i \in T: a \in P_i}})]\]

    But the random variables $\set{X_i := \mathbbm{1}_{a \in P_i}}_{i \in T}$ are independent and follow the same Bernoulli law of parameter $x_{\varphi}/h$, so the variable $X =\abs{\set{i \in T: a \in P_i}} = \sum_{i \in T} X_i \sim \Bin(\abs{T},x_{\varphi}/h)$, and thus we have that
    \[\mathbb{E}[C_e^{\varphi}(\mathcal{Q})] = \mathbb{E}[\varphi(\Bin(\abs{T},x_{\varphi}/h))] =\psi^{\varphi}_{\abs{T},h}\]

    Now we have that $0 \leq C_a^{\varphi}(\mathcal{Q}) \leq \varphi(R)$ since $\abs{\mathcal{Q}}_a\leq \abs{\mathcal{Q}} \leq R$ and $\varphi$ nondecreasing. Thanks to Azuma-Hoeffding bound, we get that:

    \[ \mathbb{P}\Big( \abs{C_a^{\varphi}(\mathcal{Q}) -\psi^{\varphi}_{\abs{T},h} n} > \eta n\Big) \leq 2 \text{exp}\Big(-\Big(\frac{\eta}{\varphi(R)}\Big)^2n\Big)\]

    Now, since there are at most $(h+1)^R$ choices of $T$ and $\mathcal{Q}$, we apply a union bound to this:
    \[ \mathbb{P}\Big(\exists C,\mathcal{Q} : \abs{C^{\varphi}(\mathcal{Q}) -\psi^{\varphi}_{\abs{T},h} n} > \eta n\Big) \leq 2(h+1)^R \text{exp}\Big(-\Big(\frac{\eta}{\varphi(R)}\Big)^2n\Big)\]

    Thus w.p. at least $9/10$, we have that $\abs{C^{\varphi}(\mathcal{Q}) -\psi^{\varphi}_{\abs{T},h} n} \leq \eta n$, since we have taken $n \geq \eta^{-2}R\varphi(R)^2\log(20(h+1))$. So there must exists some choice of $\mathcal{P}$ that satisfies the first and second constraints of partitioning systems.

    Finally, since a random choice of $\mathcal{P} = (\mathcal{P}_1,\ldots,\mathcal{P}_R)$ satisfies the desired properties, we can enumerate over all choices of $\mathcal{P}$ in time exp($Rn$log$n).$poly$(h)$ to find such a partitioning system.
\end{proof}

\section{Lemmas used in the hardness theorem \ref{theo:Hardness} and their proofs}
  \begin{lem}
  For any nonnegative nondecreasing function $f: \mathbb{N} \rightarrow \mathbb{R^+}$ with $f(k) \leq k$, we have that:
  \[ \abs{\mathbb{E}[f(\Bin(n,x/n))] - \mathbb{E}[f(\Poi(x))]} \leq \frac{x f(n)}{2n} + \frac{x^{n+1}}{n!}\]

  In particular for $\varphi$ studied in this article when $\varphi(n) = o(n)$:
  \[ \lim_{h \rightarrow  \infty} \psi^{\varphi}_{h,h} = \alpha_{\varphi}\varphi(x_{\varphi})\]

  \label{lem:UnboundBinPoi}
\end{lem}

\begin{proof}
  Thanks to \cite{TF19,Barbour84}, we have that the total variation distance between $\Bin(n,x/n)$ and $\Poi(x)$ is bounded in the following way:
  \[ \Delta(\Bin(n,x/n),\Poi(x)) \leq \frac{1 - e^{-x}}{2x} n* \Big(\frac{x}{n}\Big)^2 \leq \frac{x}{2n}\]
  Thus with $B \sim \Bin(n,x/n)$ and $P \sim \Poi(x)$:
  \begin{equation}
    \begin{aligned}
      \abs{\mathbb{E}[f(B)] - \mathbb{E}[f(P)]} &=&&  \abs{\sum_{k=0}^{+\infty}f(k)\mathbb{P}(B=k) - \sum_{k=0}^{+\infty}f(k)\mathbb{P}(P=k)}\\
      &=&&  \abs{\sum_{k=0}^{+\infty}f(k)(\mathbb{P}(B=k) - \mathbb{P}(P=k))}\\
      &\leq&& \sum_{k=0}^{+\infty}f(k)\abs{\mathbb{P}(B=k) - \mathbb{P}(P=k)}\\
      &\leq&& f(n)\Delta(\Bin(n,x/n),\Poi(x))\\
      &+&& \sum_{k=n+1}^{+\infty}f(k)\mathbb{P}(P=k)\\
      &\leq&&\frac{x f(n)}{2n}  + e^{-x}\sum_{k=n+1}^{+\infty}k\frac{x^k}{k!}\\
      &=&& \frac{x f(n)}{2n}  + xe^{-x}\sum_{k=n}^{+\infty}\frac{x^k}{k!}\\
      &\leq&& \frac{x f(n)}{2n}  + \frac{x^{n+1}}{n!} \underset{n \rightarrow \infty}{\rightarrow} 0 \text{ when } f(n) = o(n)
    \end{aligned}
  \end{equation}

  by a standard upper bound on the remainder of the exponential series.

  We get the particular case directly since $\varphi$ follows the hypothesis asked for $f$ and that $\psi^{\varphi}_{h,h} = \mathbb{E}[\varphi(\Bin(h,x_{\varphi}/h))]$ and $\alpha_{\varphi}\varphi(x_{\varphi}) = \mathbb{E}[\varphi(\Poi(x_{\varphi}))]$
\end{proof}
  
\begin{lem}
  For $\varphi$ nondecreasing concave with $\varphi(0)=0,\varphi(1)=1$, we have that the function $g_q : n \mapsto \mathbb{E}[\varphi(\Bin(n,q))]$ defined on $\mathbb{N}$ is nondecreasing concave. As a consequence, one can uses Jensen's inequality on the piecewise linear extension of $g_q$ which is also continuous.
  \label{lem:BinCon}
\end{lem}

\begin{proof}
  $\Bin(n,q) \leq_{\text{st}} \Bin(n+1,q)$ and we have that $\varphi$ is nondecreasing, so $\mathbb{E}[\varphi(\Bin(n,q))] \leq \mathbb{E}[\varphi(\Bin(n+1,q))]$, ie $g_q(n+1) - g_q(n) \geq 0$: $g_q$ is nondecreasing.

  We show then the concavity, ie. $g_q(n+2) - g_q(n+1) \leq g_q(n+1) - g_q(n)$. Call $\psi(x) = \varphi(x+1)-\varphi(x)$ which is nonincreasing since $\varphi$ concave. Let us take $X_{k,q} \sim \Bin(k,q)$. Then:

  \begin{equation}
    \begin{aligned}
      g_q(n+1) &=&& \mathbb{E}[\varphi(X_{n+1,q})]\\
      &=&& \sum_{i=0}^n \mathbb{E}[\varphi(X_{n,q}+X_{1,q})|X_{n,q}=i]\mathbb{P}(X_{n,q}=i)\\
      &=&& \sum_{i=0}^n \mathbb{E}[\varphi(i+X_{1,q}) - \varphi(i)]\mathbb{P}(X_{n,q}=i)\\
      &+&& \sum_{i=0}^n \varphi(i)\mathbb{P}(X_{n,q}=i)\\
      &=&& \sum_{i=0}^n \mathbb{E}[\varphi(i+X_{1,q}) - \varphi(i)]\mathbb{P}(X_{n,q}=i) + g_q(n)
    \end{aligned}
  \end{equation}

  Thus:

  \begin{equation}
    \begin{aligned}
      g_q(n+1) -g_q(n) &=&& \sum_{i=0}^n \mathbb{E}[\varphi(i+X_{1,q}) - \varphi(i)]\mathbb{P}(X_{n,q}=i)\\
      &=&& \sum_{i=0}^n q(\varphi(i+1) - \varphi(i))\mathbb{P}(X_{n,q}=i)\\
      &=&& q \mathbb{E}[\psi(\Bin(n,q))]
    \end{aligned}
  \end{equation}

  Then thanks to the fact that  $\Bin(n,q) \leq_{\text{st}} \Bin(n+1,q)$ and $\psi$ is nonincreasing, we have that $\mathbb{E}[\psi(\Bin(n,q))] \geq \mathbb{E}[\psi(\Bin(n+1,q))]$, ie. $g_q(n+2) - g_q(n+1) \leq g_q(n+1) - g_q(n)$.
\end{proof}
%\end{multicols}
\end{document}
